<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
	<head>
		<title>Machine Comprehension Test (MCTest)</title>
		<link type="text/css" rel="Stylesheet" href="global.css"/>
	</head>
	<body>
        <div class="page">
	    <div class="header">
            Machine Comprehension Test (MCTest)
        </div>	    
        <div class="menu">
            <span class="subtitle">A Challenge Dataset for the Machine Comprehension of Text</span>
            <span style="float:right">
            <a href="index.html">Home</a> |
            <a href="data.html">Data</a> | 
            <a href="results.html" class="active">Results</a> | 
            <a href="papers.html">Papers</a>
            </span>
        </div>
	    <div class="content">
            <br />
            <table width="100%" id="resultsTable">
                <thead id="resultsHeader">
                    <tr>
                        <td>Description</td>
                        <td>MC500 Test</td>
                        <td>MC160 Test</td>
                        <td>Score Files</td>
                    </tr>
                </thead>


                <tr>
                    <td>
                        <a href="https://arxiv.org/pdf/1603.08884.pdf">A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data.</a> 
                        by Adam Trischler, Zheng Ye, Xingdi Yuan, Jing He, Phillip Bachman, and Kaheer Suleman. In ACL 2016.
                    </td>
                    <td>71.00%</td>
                    <td>74.58%</td>
                    <td></td>
                </tr>


                <tr>
                    <td>
                        <a href="https://aclweb.org/anthology/P/P15/P15-2115.pdf">Machine comprehension with syntax, frames, and semantics.</a>
                        by Hai Wang, Mohit Bansal, Kevin Gimpel, and David McAllester. In ACL 2015.
                    </td>
                    <td>69.94%</td>
                    <td>75.27%</td>
                    <td></td>
                </tr>

                <tr>
                    <td>
                        <a href="http://aclweb.org/anthology/P15-1024">Learning answer entailing structures for machine comprehension.</a>
                        by Mrinmaya Sachan, Avinava Dubey, Eric P. Xing, and Matthew Richardson. In ACL 2015.
                    </td>
                    <td>67.83%</td>
                    <td>---</td>
                    <td></td>
                </tr>

                <tr>
                    <td>
                        <a href="http://www.aclweb.org/anthology/D/D15/D15-1197.pdf">A Strong Lexical Matching Method for the Machine Comprehension Test.</a>
                        by Ellery Smith, Nicola Greco, Matko Bo&#353;njak, and Andreas Vlachos. In EMNLP 2015.
                    </td>
                    <td>65.96%</td>
                    <td>74.27%</td>
                    <td></td>
                </tr>


                <tr>
                    <td>
                        <a href="https://aclweb.org/anthology/P/P15/P15-1121.pdf">Machine comprehension with discourse relations.</a>
                        by Karthik Narasimhan and Regina Barzilay. In ACL 2015. 
                    </td>
                    <td>63.75%</td>
                    <td>73.23%</td>
                    <td></td>
                </tr>


                <tr>
                    <td>Baseline: SW+D + RTE</td>
                    <td>63.33%</td>
                    <td>69.27%</td>
                    <td><a href="scores/RTE_Plus_BaselineSW_D.scores.zip">RTE_Plus_Ba...</a></td>
                </tr>

                <tr>
                    <td>Baseline: Sliding Window plus Distance (SW+D)</td>
                    <td>59.93%</td>
                    <td>68.02%</td>
                    <td><a href="scores/Baseline_SW_D.scores.zip">Baseline_SW_D</a></td>
                </tr>

                <!-- Class project, not included for now
                <tr>
                    <td>Machine Comprehension Using Robust Rule-Based Features and Multiple-Sentence Enhancing. Class project, 2015</td>
                    <td>56.1(59.5?)</td>
                    <td></td>
                    <td></td>
                </tr>
                    -->

                <tr>
                    <td>Baseline: RTE (using <a href="http://u.cs.biu.ac.il/~nlp/downloads/biutee/protected-biutee.html">BIUTEE</a>)</td>
                    <td>55.01%</td>
                    <td>57.92%</td>
                    <td><a href="scores/RTE.scores.zip">RTE</a></td>
                </tr>

                <tr>
                    <td>Baseline: Sliding Window (SW)</td>
                    <td>54.28%</td>
                    <td>58.26%</td>
                    <td><a href="scores/Baseline_SW.scores.zip">Baseline_SW</a></td>
                </tr>

                <tr>
                    <td>
                        <a href="https://www.aclweb.org/anthology/W/W16/W16-0103.pdf">Attention-Based Convolutional Neural Network for Machine Comprehension.</a>
                        by Wenpeng Yin, Sebastian Ebert, Hinrich Sch&#252;utze. In NAACL 2016.
                    </td>
                    <td>52.9%</td>
                    <td>63.1%</td>
                    <td></td>
                </tr>

                <!-- Class project, not included for now
                <tr>
                    <td>
                        Answering Reading Comprehension Using Memory Networks
                        Darshan Kapashi
                        Pararth Shah                    
                        (class project. Seems to be 2015)
                    </td>
                    <td>40.1%</td>
                    <td></td>
                    <td></td>
                </tr>
                    -->

            </table>

            <p><strong>Add your results</strong>: This is the set of results as far as we are aware, but it's hard to track
            all of the results that may have been published on the data set. If you have results on MCTest that you would like
            to appear above (or if you spot an error) <a href="mailto:mattri@microsoft.com">email us</a> with your results.
            </p>

            <p><strong>Score Files</strong>: The score file format is specified in the
                <a href="README.txt">README.txt</a> contained in the <a href="data.html">MCTest data</a>. 
                A score file provides the given algorithm's score for each answer. We hope this will enable more 
                rapid progress on MCTest &ndash; by enabling each new algorithm to build on top of previous
                results, by allowing pairwise statistical significance testing, and by allowing
                anyone to investigate what kind of errors are being made by previous work.
            </p>
            <p>
            <strong>Note</strong>: The accuracies reported here differ from those reported
            in the <a href="MCTest_EMNLP2013.pdf">paper</a>. The primary reason is in how ties are dealt with. Here, we 
            report accuracies using partial credit. That is, if three answers tie for highest score, 
            and one of them was right, then the algorithm gets 1/3 points for that question. This differs from 
            the published results which were computed by random tie-breaking. Partial credit
            is deterministic and more reproducable by others, as well as being less noisy. For this reason,
            we suggest that any results published using this data also use partial credit in the case
            of ties.
            </p>
            <p>Further, once we were using partial credit for tie-breaking, we were able to see that 
            there was an improvement in accuracy on the development set using a weight other than
            1 for combinining the sliding window and distance baselines (previously, this improvement was
            lost in the random noise induced by random tie breaking). The best weight for MC500
            was 11, and for MC160 it was 10 (for MC160 there is actually a tie for accuracy among weights 1
            and 10, among others, so we selected 10 on the assumption that the best weight
            on different datasets should be similar, and MC500 had more data and indicated an ideal
            weight of 11). This weight tuning was done purely on the development sets.
            </p>
            <p>Finally, there is a bug in the paper. The correct implmentation of Algorithm 2 (Distance Based Baseline)
                is to take an <em>average</em>, across all question words, of the minimum distance between that question word
                and one of the answer words. The paper accidentally says to take the <em>minimum</em> across the
                question words. 
            </p>
            <p>The original score files for the SW+D baseline, with a combination weight of 1, and taking the minimum instead of average
                when computing the distance based baseline, can be downloaded here: <a href="scores/BaselineInPaper_SW_D.scores.zip">BaselineInPaper_SW_D</a>
            </p>
            <p>UPDATE 11/5/2014: Fixed Baseline_SW_D.scores.zip, which had accidentally been created using a MC500 baseline
            combination weight of 10 instead of 11 and was normalizing the distance-based scores by |P| rather than |P|-1.</p>

            <!--footer code begin-->
            <div style="font-family: Verdana; height:25px; padding-top:5px; font-size:70%;">
            &copy; Microsoft Corporation. All rights reserved.
            </div>
            <!--footer code end-->
        </div>
        </div>
    </body>
</html>

